# Batch Data Pipeline Using Apache Airflow, Spark, AWS EMR, and Snowflake

I built this project with the object of learning how to build batch data pipeline by integrating

✅ Airflow to orchestrate and manage the data pipeline

✅ AWS EMR for the heavy data processing

✅ Snowflake for Data Warehousing

✅ Use Airflow to create the EMR cluster, and then terminate once the processing is complete to save on cost.


## Data Pipeline Architecture 

<img width="724" alt="Screenshot 2025-05-05 at 7 59 36 PM" src="https://github.com/user-attachments/assets/1daf24b8-fa78-4366-b8ba-c6e042b20bb6" />
